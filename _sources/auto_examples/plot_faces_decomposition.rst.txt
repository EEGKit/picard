.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_faces_decomposition.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_examples_plot_faces_decomposition.py:


================================================
Comparison of Picard-O and FastICA on faces data
================================================

This example compares FastICA and Picard-O:

Pierre Ablin, Jean-Fran√ßois Cardoso, Alexandre Gramfort
"Faster ICA under orthogonal constraint"
ICASSP, 2018
https://arxiv.org/abs/1711.10873


On the figure, the number above each bar corresponds to the final gradient
norm.


.. code-block:: default


    # Author: Pierre Ablin <pierre.ablin@inria.fr>
    #         Alexandre Gramfort <alexandre.gramfort@inria.fr>
    # License: BSD 3 clause


    import numpy as np
    from time import time
    import matplotlib.pyplot as plt
    from sklearn.datasets import fetch_olivetti_faces
    from sklearn.decomposition import fastica

    from picard import picard


    print(__doc__)

    image_shape = (64, 64)
    rng = np.random.RandomState(0)


    def gradient_norm(Y):
        psiY = np.tanh(Y)
        psidY_mean = 1 - np.mean(psiY ** 2, axis=1)
        g = np.dot(psiY, Y.T) / Y.shape[1]
        signs = np.sign(psidY_mean - np.diag(g))
        g *= signs[:, None]
        g = (g - g.T) / 2
        return np.linalg.norm(g)









Load faces data


.. code-block:: default

    dataset = fetch_olivetti_faces(shuffle=True, random_state=rng)
    faces = dataset.data

    n_samples, n_features = faces.shape

    # global centering
    faces_centered = faces - faces.mean(axis=0)

    # local centering
    faces_centered -= faces_centered.mean(axis=1).reshape(n_samples, -1)

    print("Dataset consists of %d faces" % n_samples)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /home/circleci/scikit_learn_data
    Dataset consists of 400 faces




Run Picard-O and FastICA for different number of sources, and store the
elapsed time.


.. code-block:: default



    dimensions = [5, 10, 40, 60]

    algorithms = [picard, fastica]
    names = ['PicardO', 'FastICA']
    colors = ['b', 'orange']

    running_times = dict(FastICA=[], PicardO=[])
    gradients = dict(FastICA=[], PicardO=[])
    for n_components in dimensions:
        for name, algorithm in zip(names, algorithms):

            if name == 'FastICA':
                kwargs = dict(X=faces_centered.T, n_components=n_components,
                              random_state=rng, max_iter=500, tol=1e-10)
            else:
                kwargs = dict(X=faces_centered, n_components=n_components,
                              max_iter=500, tol=1e-5, random_state=rng)
            t0 = time()
            K, W, Y = algorithm(**kwargs)
            running_times[name].append(time() - t0)
            gradients[name].append(gradient_norm(Y))






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/.local/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.
      warnings.warn('FastICA did not converge. Consider increasing '
    /home/circleci/.local/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.
      warnings.warn('FastICA did not converge. Consider increasing '




Plot the results


.. code-block:: default



    def autolabel(rects, gradient_list):
        """
        Attach a text label above each bar displaying its height
        """
        for rect, gradient_norm in zip(rects, gradient_list):
            height = rect.get_height()
            g_string = '%.1e' % gradient_norm
            g_string = g_string[:5] + g_string[6:]
            ax.text(rect.get_x() + rect.get_width() / 2., height,
                    'G=%.1e' % gradient_norm, fontsize=8,
                    ha='center', va='bottom')


    fig, ax = plt.subplots()
    ind = np.arange(len(dimensions))
    width = 0.8
    for i, (name, color) in enumerate(zip(names, colors)):
        rect = ax.bar(2 * ind - 0.05 + i * (width + 0.1), running_times[name],
                      width=width, color=color, label=name)
        autolabel(rect, gradients[name])
    ax.set_xticks(2 * ind + width / 2)
    ax.set_xticklabels((str(n_components) for n_components in dimensions))
    plt.legend()
    plt.xlabel('Number of sources')
    plt.ylabel('Time (sec.)')
    plt.show()



.. image:: /auto_examples/images/sphx_glr_plot_faces_decomposition_001.png
    :alt: plot faces decomposition
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/project/examples/plot_faces_decomposition.py:120: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
      plt.show()





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  15.491 seconds)


.. _sphx_glr_download_auto_examples_plot_faces_decomposition.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_faces_decomposition.py <plot_faces_decomposition.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_faces_decomposition.ipynb <plot_faces_decomposition.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
